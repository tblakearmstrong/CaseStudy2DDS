library(dplyr)
library(ggplot2)
library(lubridate)
library(naniar)
library(caret)
library(e1071)

###-----------------------------------------------------------###LOAD AND CLEAN###-------------------------------------------------------------------###
# Load the test dataset
wine_prediction_raw <- read.csv("https://raw.githubusercontent.com/tblakearmstrong/CaseStudy2DDS/refs/heads/main/RawFiles/Wine%20Test%20Set.csv", header = TRUE)
wine_prediction_raw$quality <- NA_integer_ #Add the column so we can rbind later to make a full dataset
str(wine_prediction_raw)

# Load the train dataset
wine_train_raw <- read.csv("https://raw.githubusercontent.com/tblakearmstrong/CaseStudy2DDS/refs/heads/main/RawFiles/Wine%20Train.csv", header=TRUE)
str(wine_train_raw)

# rbind datasets to impute later
wine_total_raw <- rbind(wine_train_raw, wine_prediction_raw)
str(wine_total_raw)

# Load the locations/type of all wines (with missing values, need to impute)
wine_type_location <- read.csv("https://raw.githubusercontent.com/tblakearmstrong/CaseStudy2DDS/refs/heads/main/RawFiles/Wine%20Types%20And%20Locations.csv", header = TRUE)
str(wine_type_location)


# Look at missing values
missing_type_location <- tibble(
  missing_type = sum(wine_type_location$type==""),
  missing_location = sum(wine_type_location$location==""))
print(missing_type_location)


# Fix the missing values in wine_type_location before merging with other datasets going from "" to NA
wine_type_location <- wine_type_location %>% 
  mutate(type=ifelse(type=="",NA,type))


# Merge total raw dataset with the type and location
wine_full_set <- merge(wine_total_raw, wine_type_location, by = "ID")
str(wine_train)

# Plot missing variables using naniar package
gg_miss_var(wine_full_set)


###-----------------------------------------------------###FIX MISSING "type" VALUES###---------------------------------------------------------------###
### Impute missing wine types using the mice package

library(minqa)
library(mice)
library(gridExtra)

# Setting dataframe to impute 
wine_type_impute <- wine_full_set %>% 
  select(fixed_acidity, volatile_acidity, residual_sugar, chlorides, free_sulfur_dioxide, total_sulfur_dioxide, density, pH, sulphates, alcohol, type, location)
str(wine_type_impute)

####Try to rotate labels so that it is readable####
md.pattern(wine_type_impute) # Matches 175 to what was calculated above...


# Making sure type is a factor
wine_type_impute$type <- as.factor(wine_type_impute$type)


# Perform imputation using mice with logistic regression (logreg) for the 'type' column
imputed_data <- mice(wine_type_impute, method = "logreg", m = 5)


# Setup dataframe to be able to plot histogram by type
mice_imputed <- data.frame(
  original = wine_full_set$type,  # The original type column
  imputed_logreg = complete(imputed_data, action = 1)$type  # First imputation (logreg)
  )


h1 <- ggplot(mice_imputed, aes(x = original)) +
  geom_bar(fill = "#ad1538", color = "#000000", position = "identity") +
  ggtitle("Original Distribution") +
  theme_classic() +
  scale_x_discrete(labels = c("Red", "White"))+
  geom_text(stat = "count", aes(label = ..count..), vjust = -0.5, color = "black")+
  scale_y_continuous(limits = c(0, 5500))

h2 <- ggplot(mice_imputed, aes(x = imputed_logreg)) +
  geom_bar(fill = "#15ad4f", color = "#000000", position = "identity") +
  ggtitle("Logistic Regression Imputed Distribution") +
  theme_classic() +
  scale_x_discrete(labels = c("Red", "White"))+
  geom_text(stat = "count", aes(label = ..count..), vjust = -0.5, color = "black") +
  scale_y_continuous(limits = c(0, 5500))

# Combine plots into a grid for easy comparison
grid.arrange(h1, h2, nrow = 2)



# Extract the first imputation (action = 1) for the 'type' column from the imputed data
imputed_type <- complete(imputed_data, action = 1)$type

# Add the imputed 'type' column back into the original wine_full_set dataframe
wine_full_set$type_imputed <- imputed_type
str(wine_full_set)
summary(wine_full_set)
# Make sure everything is populated that is supposed to be at this step...
gg_miss_var(wine_full_set)

# Split back out into the original train and test sets
#Train stops at ID = 5463
wine_train <- wine_full_set[1:5463,]
str(wine_train)

#Test starts at ID = 5464 until the end
wine_quality_prediction <- wine_full_set[5464:nrow(wine_full_set),]
str(wine_test)


###-------------------------------------------------------BUILD MODEL--------------------------------------------------------------------------------###

###-------------------------------Naive Bayes loop over every combination and find the lowest MAE---------------------------------------
library(e1071)     
library(tidyverse)
library(caret)     
library(purrr)     
  
# Split data into training and testing sets
set.seed(123)
split <- 0.8
train_indices = sample(seq(1, nrow(wine_train)), round(split * nrow(wine_train)))
wine_train_model <- wine_train[train_indices, ]
wine_test_model  <- wine_train[-train_indices, ]
  
  # Ensure quality is numeric for calculating MAE
wine_train_model$quality <- as.integer(wine_train_model$quality)
  
# Define predictors
predictors <- c("fixed_acidity", "volatile_acidity", "citric_acid", "residual_sugar", "chlorides", 
                "free_sulfur_dioxide", "total_sulfur_dioxide", "density", "pH", "sulphates", "type_imputed", "location")
  
# Function to evaluate a Naive Bayes model and return MAE
evaluate_nb_model <- function(predictors, wine_train_model, wine_test_model) {
  # Create the formula dynamically for Naive Bayes model
  formula <- as.formula(paste("quality ~", paste(predictors, collapse = " + ")))
  
  # Train the Naive Bayes model
  nb_model <- naiveBayes(formula, data = wine_train_model)
  
  # Make predictions on the test set
  nb_pred <- predict(nb_model, newdata = wine_test_model)
  
  # Convert predicted factors to numeric (for MAE calculation)
  nb_pred_numeric <- as.numeric(as.character(nb_pred))
  
  # Calculate Mean Absolute Error (MAE)
  mae <- mean(abs(nb_pred_numeric - wine_test_model$quality))  # MAE calculation
  
  return(mae)
}
  
# Create all combinations of predictor variables
all_combinations <- unlist(lapply(1:length(predictors), function(i) combn(predictors, i, simplify = FALSE)), recursive = FALSE)
  
# Loop over all combinations and evaluate each model
results <- map_dfr(all_combinations, function(combo) {
  mae <- evaluate_nb_model(combo, wine_train_model, wine_test_model)
  data.frame(Variables = paste(combo, collapse = ", "), MAE = mae)
})
  
# Find the combination with the lowest MAE
best_model <- results[which.min(results$MAE), ]
  
# Print out the best combination and its MAE
cat("Best combination of variables:", best_model$Variables, "\n")
cat("Best MAE:", best_model$MAE, "\n")


###---------------Same thing - Naive Bayes loop over every combination and find the lowest MAE by splitting by wine type---------------

library(e1071)     
library(tidyverse)
library(caret)     
library(purrr)     

# Ensure quality is numeric for calculating MAE
wine_train$quality <- as.integer(wine_train$quality)
wine_test$quality <- as.integer(wine_test$quality)


# Split data into training and testing sets
set.seed(123)
split <- 0.8
train_indices = sample(seq(1, nrow(wine_train)), round(split * nrow(wine_train)))
wine_train_model <- wine_train[train_indices, ]
wine_test_model  <- wine_train[-train_indices, ]


# Define predictors (removing `type_imputed` or any `type` column)
predictors <- c("fixed_acidity", "volatile_acidity", "citric_acid", "residual_sugar", "chlorides", 
                "free_sulfur_dioxide", "total_sulfur_dioxide", "density", "pH", "sulphates", "location")

# Function to evaluate a Naive Bayes model and return MAE
evaluate_nb_model <- function(predictors, wine_train_model, wine_test_model) {
  # Create the formula dynamically for Naive Bayes model
  formula <- as.formula(paste("quality ~", paste(predictors, collapse = " + ")))
  
  # Train the Naive Bayes model
  nb_model <- naiveBayes(formula, data = wine_train_model)
  
  # Make predictions on the test set
  nb_pred <- predict(nb_model, newdata = wine_test_model)
  
  # Convert predicted factors to numeric (for MAE calculation)
  nb_pred_numeric <- as.numeric(as.character(nb_pred))
  
  # Calculate Mean Absolute Error (MAE)
  mae <- mean(abs(nb_pred_numeric - wine_test_model$quality))  # MAE calculation
  
  return(mae)
}

# Split the dataset by wine type (Red and White)
wine_train_red <- wine_train_model %>% filter(type_imputed == "red")
wine_test_red <- wine_test_model %>% filter(type_imputed == "red")

wine_train_white <- wine_train_model %>% filter(type_imputed == "white")
wine_test_white <- wine_test_model %>% filter(type_imputed == "white")

# Create all combinations of predictor variables
all_combinations <- unlist(lapply(1:length(predictors), function(i) combn(predictors, i, simplify = FALSE)), recursive = FALSE)

# Function to evaluate the model for each wine type
evaluate_for_wine_type <- function(wine_type, wine_train_model, wine_test_model) {
  results_for_type <- map_dfr(all_combinations, function(combo) {
    mae <- evaluate_nb_model(combo, wine_train_model, wine_test_model)
    data.frame(Wine_Type = wine_type, Variables = paste(combo, collapse = ", "), MAE = mae)
  })
  return(results_for_type)
}

# Evaluate for both Red and White wines separately
results_red <- evaluate_for_wine_type("red", wine_train_red, wine_test_red)
results_white <- evaluate_for_wine_type("white", wine_train_white, wine_test_white)

# Combine the results for both Red and White wines
all_results <- bind_rows(results_red, results_white)

# Find the combination with the lowest MAE for each wine type
best_model_red <- results_red[which.min(results_red$MAE), ]
best_model_white <- results_white[which.min(results_white$MAE), ]

# Print out the best combinations and their MAEs
cat("Best combination of variables for Red Wine:", best_model_red$Variables, "\n")
cat("Best MAE for Red Wine:", best_model_red$MAE, "\n")

cat("Best combination of variables for White Wine:", best_model_white$Variables, "\n")
cat("Best MAE for White Wine:", best_model_white$MAE, "\n")
